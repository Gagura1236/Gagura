import streamlit as st
import pandas as pd
import json
import torch
import google.generativeai as genai
import requests # ç”¨æ–¼ Pollinations
from sentence_transformers import SentenceTransformer, util
from langchain_groq import ChatGroq

# --- 1. é é¢åŸºæœ¬è¨­å®š ---
st.set_page_config(page_title="æ˜“ç¶“æ™ºæ…§å°èˆª", page_icon="â˜¯ï¸", layout="centered")

# è‡ªå®šç¾© CSS
st.markdown("""
<style>
    .stTextInput > label {font-size:110%; font-weight:bold;}
    .stTextArea > label {font-size:110%; font-weight:bold;}
    
    .hexagram-box {
        background-color: #FFF8E1; 
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #D97706;
        margin: 20px 0;
        font-family: "KaiTi", "BiauKai", serif;
        color: #2e2e2e;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. è¼‰å…¥è³‡æ–™èˆ‡æ¨¡å‹ ---
@st.cache_resource
def load_resources():
    try:
        df = pd.read_json('yi_jing_data.json')
        df['search_text'] = df['modern_translation'] + " " + df['meaning_keywords']
    except Exception as e:
        st.error(f"æ‰¾ä¸åˆ° yi_jing_data.jsonï¼Œè«‹ç¢ºèªæª”æ¡ˆä½ç½®ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
        return None, None, None

    model = SentenceTransformer('shibing624/text2vec-base-chinese')
    embeddings = model.encode(df['search_text'].tolist(), convert_to_tensor=True)
    
    return df, model, embeddings

df, embed_model, doc_embeddings = load_resources()

# --- 3. å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.title("ğŸ”® è¨­å®š")
    
    st.subheader("1. è¬›çµ¦ä½ è½ (æ–‡å­—æ¨ç†)")
    groq_api_key = st.text_input("Groq API Key", type="password", help="gsk_é–‹é ­")
    st.markdown("[å–å¾— Groq Key](https://console.groq.com/keys)")

    st.divider()

    st.subheader("2. ç•«çµ¦ä½ çœ‹ (åœ–åƒç”Ÿæˆ)")
    image_model_choice = st.radio(
        "é¸æ“‡ç¹ªåœ–æ¨¡å‹",
        [
            "Pollinations (å…é‘°åŒ™/å…è²»/æ¨è–¦) ğŸ‘", 
            "Google Imagen 3 (é«˜å“è³ª/éœ€æ¬Šé™)", 
            "OpenAI DALLÂ·E 3 (ä»˜è²»/é«˜å“è³ª)"
        ]
    )

    if image_model_choice == "OpenAI DALLÂ·E 3 (ä»˜è²»/é«˜å“è³ª)":
        openai_api_key = st.text_input("OpenAI API Key", type="password", key="openai_key")
        google_api_key = None
        st.markdown("[å–å¾— OpenAI Key](https://platform.openai.com/api-keys)")
        
    elif image_model_choice == "Google Imagen 3 (é«˜å“è³ª/éœ€æ¬Šé™)":
        google_api_key = st.text_input("Google API Key", type="password", help="AIzaé–‹é ­", key="google_key")
        openai_api_key = None
        st.markdown("[å–å¾— Google API Key](https://aistudio.google.com/app/apikey)")
        
    else: # Pollinations
        st.info("âœ¨ ä½¿ç”¨ Pollinations.ai æŠ€è¡“ï¼Œå®Œå…¨å…è²»ï¼Œç„¡éœ€è¨­å®š API Keyã€‚")
        google_api_key = None
        openai_api_key = None

    st.divider()

    role = st.selectbox(
        "é¸æ“‡ AI è§£å¦é¢¨æ ¼",
        ["æ™ºæ…§é•·è€… (æº«æš–æŒ‡å¼•)", "åš´è‚…è€å¸« (ç°¡æ½”æœ‰åŠ›)", "å¿ƒç†è«®å•†å¸« (åŒç†åˆ†æ)", "ç™½è©±ç¿»è­¯æ©Ÿ (ç›´ç™½æ˜“æ‡‚)"]
    )
    
    st.caption("Designed for I Ching AI Project")

# --- 4. ä¸»ä»‹é¢é‚è¼¯ ---
st.title("â˜¯ï¸ æ˜“ç¶“æ™ºæ…§å°è©±æ©Ÿå™¨äºº")
st.markdown("è«‹åœ¨å¿ƒä¸­é»˜å¿µæ‚¨çš„ç–‘å•ï¼Œæè¿°ç•¶ä¸‹çš„è™•å¢ƒï¼ŒAI å°‡ç‚ºæ‚¨æ„Ÿæ‡‰æœ€é©åˆçš„ä¸€å¦ã€‚")

with st.form("query_form"):
    col1, col2 = st.columns(2)
    with col1:
        user_event = st.text_area("1. ç™¼ç”Ÿäº†ä»€éº¼äº‹ï¼Ÿè«‹å„˜é‡æè¿°ç´°ç¯€èˆ‡æƒ…å¢ƒ", height=400, placeholder="ä¾‹å¦‚ï¼šå‰›æ›æ–°å·¥ä½œï¼ŒåŒäº‹å¾ˆé›£ç›¸è™•...")
    with col2:
        user_question = st.text_area("2. æƒ³å•ä»€éº¼ï¼Ÿå„˜é‡èšç„¦åœ¨è‡ªå·±å¯ä»¥æ”¹è®Šçš„åœ°æ–¹", height=400, placeholder="ä¾‹å¦‚ï¼šæˆ‘è©²é›¢è·é‚„æ˜¯ç¹¼çºŒæ’ä¸‹å»ï¼Ÿ")
    
    submitted = st.form_submit_button("ğŸ” æ˜“ç¶“å“²å­¸è§€")

# --- 5. åŸ·è¡Œé‹ç®— ---
if submitted:
    if not groq_api_key:
        st.warning("âš ï¸ è«‹å…ˆåœ¨å·¦å´å´é‚Šæ¬„è¼¸å…¥ Groq API Key æ‰èƒ½é‹ä½œå–”ï¼")
    elif not user_event or not user_question:
        st.warning("âš ï¸ è«‹å®Œæ•´è¼¸å…¥ã€Œäº‹ä»¶ã€èˆ‡ã€Œæƒ³å•çš„å•é¡Œã€ã€‚")
    else:
        full_query = f"äº‹ä»¶ï¼š{user_event}ã€‚ç–‘å•ï¼š{user_question}"
        
        with st.spinner('æ­£åœ¨é€£çµå‚³æ‰¿åƒå¹´çš„æ™ºæ…§ï¼Œæ˜“ç¶“ä¸æ˜¯ç®—å‘½ï¼Œæ˜¯å‘Šè¨´ä½ ç›®å‰è™•å¢ƒåœ¨å“ªå€‹ç¯€é»...'):
            # A. å‘é‡æœå°‹
            query_embedding = embed_model.encode(full_query, convert_to_tensor=True)
            cos_scores = util.cos_sim(query_embedding, doc_embeddings)[0]
            best_match_idx = torch.argmax(cos_scores).item()
            result = df.iloc[best_match_idx]
            
            hex_name = f"{result['hexagram']} {result['position']}"
            original_text = result['original_text']
            translation = result['modern_translation']
            
        st.success(f"åœå¾—ï¼šã€ {hex_name} ã€‘")
        st.markdown(f"""
        <div class="hexagram-box">
            <b>ğŸ“œ ç¶“æ–‡ï¼š</b>{original_text}<br>
            <b>ğŸ“– è§£é‡‹ï¼š</b>{translation}
        </div>
        """, unsafe_allow_html=True)

        # B. LLM è§£è®€
        with st.spinner('æ™ºæ…§ä¹‹æ›¸æ­£åœ¨æ’°å¯«è§£ç±¤...'):
            try:
                chat = ChatGroq(temperature=0.7, groq_api_key=groq_api_key, model_name="llama-3.3-70b-versatile")
                
                system_prompt = f"ä½ ç¾åœ¨æ˜¯ä¸€ä½ç²¾é€šæ˜“ç¶“çš„{role}ã€‚è«‹æ ¹æ“šæä¾›çš„å¦è±¡è³‡è¨Šï¼Œå›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚"
                
                human_prompt = f"""
                ä½¿ç”¨è€…æƒ…å¢ƒï¼š{full_query}
                
                å°æ‡‰æ˜“ç¶“çˆ»è¾­çµæœï¼š
                å¦åï¼š{hex_name}
                åŸæ–‡ï¼š{original_text}
                ç™½è©±æ„æ¶µï¼š{translation}
                
                è«‹ä¾ç…§ä»¥ä¸‹ Markdown æ ¼å¼çµæ§‹é€²è¡Œ**è©³ç›¡ä¸”æ·±å…¥**çš„è§£è®€ï¼ˆç¸½å­—æ•¸è«‹è¶…é 600 å­—ï¼‰ï¼š
                
                ### 1. ğŸ” å¦è±¡æ·±åº¦è§£æ
                - é€™ä¸€éƒ¨ä»½è‡³å°‘ 300 å­—ã€‚
                - è«‹å‹™å¿…å°‡æ˜“ç¶“åŸæ–‡å®Œæ•´å¯«å‡ºï¼Œä¸¦è§£é‡‹å…¶æ„è±¡ï¼ˆä¾‹å¦‚ï¼šå±±ä¸‹æœ‰ç«ã€é›·åœ¨å¤©ä¸Šç­‰ä»£è¡¨ä»€éº¼è‡ªç„¶ç¾è±¡ï¼Ÿï¼‰ã€‚
                - çµåˆæ˜“ç¶“åŸæ–‡ï¼Œåˆ†æç‚ºä»€éº¼é€™å€‹å¦è±¡ç²¾æº–å°æ‡‰åˆ°äº†ä½¿ç”¨è€…çš„ã€Œ{user_event}ã€æƒ…å¢ƒï¼Ÿ
                - è§£æé€™ä¸€çˆ»ï¼ˆ{result['position']}ï¼‰åœ¨æ•´å€‹å¦ä¸­çš„ä½ç½®æ„ç¾©ï¼ˆæ˜¯å‰æ˜¯å‡¶ï¼Ÿæ˜¯å‰›é–‹å§‹é‚„æ˜¯å¿«çµæŸï¼Ÿï¼‰ã€‚

                ### 2. ğŸ’¡ å±€å‹¢åˆ¤è®€èˆ‡å¿ƒç†å»ºè¨­
                - åˆ†ææ­¤åˆ»ã€Œ{user_question}ã€èƒŒå¾Œçš„å¿ƒç†ç‹€æ…‹ã€‚
                - é»å‡ºç›®å‰å±€å‹¢çš„æ½›åœ¨é¢¨éšªæ˜¯ä»€éº¼ï¼Ÿ
                - æœ‰ä»€éº¼çœ‹ä¸è¦‹çš„æ©Ÿæœƒé»æ­£åœ¨èŒèŠ½ï¼Ÿ

                ### 3. ğŸš€ å…·é«”è¡Œå‹•æŒ‡å— (Step-by-Step)
                - è«‹çµ¦å‡º 3 åˆ° 5 å€‹å…·é«”çš„åŸ·è¡Œæ­¥é©Ÿï¼Œä¸è¦åªæœ‰ç©ºæ³›çš„å»ºè­°ã€‚
                - åˆ†åˆ¥é‡å°ã€ŒçŸ­æœŸï¼ˆç¾åœ¨ç«‹åˆ»åšï¼‰ã€èˆ‡ã€Œé•·æœŸï¼ˆæœªä¾†ä¸€å€‹æœˆï¼‰ã€çµ¦äºˆå»ºè­°ã€‚

                ### 4. âš ï¸ æé†’è­¦èª
                - å¦‚æœä¸è½å‹¸å‘Šï¼Œæœ€å£çš„æƒ…æ³æœƒæ˜¯å¦‚ä½•ï¼Ÿ
                - æé†’ä½¿ç”¨è€…åœ¨å¿ƒæ…‹ä¸Šè¦é¿å…çš„ç›²é»ï¼ˆä¾‹å¦‚ï¼šé¿å…æ€¥èºã€é¿å…è²ªå¿ƒï¼‰ã€‚

                ### 5. ğŸŒˆ æ™ºæ…§çµèª
                (è«‹åœ¨æ­¤è™•ç›´æ¥æ’°å¯«ä¸€æ®µæº«æš–ã€å……æ»¿åŠ›é‡çš„ç¥ç¦æˆ–å®šå¿ƒä¸¸ï¼Œä¸éœ€è¦åˆ—é»ï¼Œä¹Ÿä¸è¦é‡è¤‡æ­¤æŒ‡ä»¤)

                ---
                (é‡è¦ï¼šè«‹åœ¨å›ç­”çš„æœ€å¾Œé¢ï¼Œç¨ç«‹ä¸€è¡Œï¼Œæä¾›ä¸€æ®µç´„ 50-80 å€‹å–®å­—çš„ã€Œè‹±æ–‡ã€åœ–åƒç”Ÿæˆæç¤ºè© (Image Prompt)ã€‚é€™æ®µæç¤ºè©è¦èƒ½è¦–è¦ºåŒ–å‘ˆç¾ä½ ä¸Šè¿°ã€Œå¦è±¡æ·±åº¦è§£æã€ä¸­çš„æ ¸å¿ƒæ„å¢ƒèˆ‡æ°›åœï¼Œé¢¨æ ¼è¦æ±‚ç‚ºï¼šå¯«å¯¦é¢¨æ™¯ç•«çµåˆå¾Œç¾ä»£è—è¡“èˆ‡å“²å­¸æ„Ÿã€‚è«‹å‹™å¿…ä»¥ "IMAGE_PROMPT:" é–‹é ­ã€‚)
                """
                
                messages = [("system", system_prompt), ("human", human_prompt)]
                
                # å‘¼å« LLM
                ai_response = chat.invoke(messages)
                full_response_text = ai_response.content

                # è§£æå›æ‡‰ï¼Œåˆ†é›¢åœ–ç‰‡æç¤ºè©
                if "IMAGE_PROMPT:" in full_response_text:
                    parts = full_response_text.split("IMAGE_PROMPT:")
                    text_display = parts[0].strip()
                    image_prompt_en = parts[1].strip()
                else:
                    text_display = full_response_text
                    image_prompt_en = None

                # é¡¯ç¤ºæ–‡å­—
                st.markdown("### ğŸ’¡ æ™ºæ…§æŒ‡å¼•")
                st.write(text_display)
                st.divider()

                # C. åœ–åƒç”Ÿæˆé‚è¼¯ (ä¸‰å¤§é–€æ´¾)
                if image_prompt_en:
                    # é–€æ´¾ 1: Pollinations (å…é‘°åŒ™/æœ€ç©©)
                    if image_model_choice == "Pollinations (å…é‘°åŒ™/å…è²»/æ¨è–¦) ğŸ‘":
                        with st.spinner('æ­£åœ¨æç¹ªå¿ƒéˆåœ–é¨° (Pollinations)...'):
                            try:
                                # Pollinations æ˜¯é€é URL ç›´æ¥ç”Ÿåœ–ï¼Œç„¡éœ€ SDK
                                safe_prompt = image_prompt_en.replace(" ", "%20")
                                # åŠ å…¥ seed è®“åœ–ç‰‡æ›´éš¨æ©Ÿ
                                import random
                                seed = random.randint(1, 99999)
                                image_url = f"https://image.pollinations.ai/prompt/A%20philosophical%20Chinese%20ink%20painting%20{safe_prompt}?nologo=true&seed={seed}&width=1024&height=1024"
                                st.image(image_url, caption=f"ã€{hex_name}ã€‘å¿ƒéˆæ„å¢ƒåœ–", use_column_width=True)
                            except Exception as e:
                                st.error(f"Pollinations åœ–ç‰‡ç”Ÿæˆå¤±æ•—ï¼š{e}")

                    # é–€æ´¾ 2: Google Imagen 3
                    elif image_model_choice == "Google Imagen 3 (é«˜å“è³ª/éœ€æ¬Šé™)" and google_api_key:
                        with st.spinner('Imagen æ­£åœ¨æç¹ªå¿ƒéˆåœ–é¨°...'):
                            try:
                                genai.configure(api_key=google_api_key)
                                imagen_model = genai.ImageGenerationModel("imagen-3.0-generate-001")
                                result = imagen_model.generate_images(
                                    prompt=f"A philosophical and artistic illustration style, Chinese ink painting aesthetic combined with abstract modern art. {image_prompt_en}",
                                    number_of_images=1,
                                )
                                st.image(result.images[0], caption=f"ã€{hex_name}ã€‘Google Imagen 3 æ„å¢ƒåœ–", use_column_width=True)
                            except AttributeError:
                                st.error("âŒ ä½ çš„ Google å¥—ä»¶ç‰ˆæœ¬éèˆŠã€‚è«‹åœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œ `pip install -U google-generativeai` æ›´æ–°ã€‚")
                            except Exception as e:
                                st.error(f"Google åœ–ç‰‡ç”Ÿæˆå¤±æ•—ï¼š{e} (å¯èƒ½æ˜¯å¸³è™Ÿæ¬Šé™å•é¡Œï¼Œè«‹æ”¹ç”¨ Pollinations)")

                    # é–€æ´¾ 3: OpenAI DALL-E 3
                    elif image_model_choice == "OpenAI DALLÂ·E 3 (ä»˜è²»/é«˜å“è³ª)" and openai_api_key:
                        with st.spinner('DALLÂ·E æ­£åœ¨æç¹ªå¿ƒéˆåœ–é¨°...'):
                            try:
                                from openai import OpenAI
                                client = OpenAI(api_key=openai_api_key)
                                response = client.images.generate(
                                    model="dall-e-3",
                                    prompt=f"A philosophical and artistic illustration style, Chinese ink painting aesthetic combined with abstract modern art. {image_prompt_en}",
                                    size="1024x1024",
                                    quality="standard",
                                    n=1,
                                )
                                image_url = response.data[0].url
                                st.image(image_url, caption=f"ã€{hex_name}ã€‘DALLÂ·E 3 æ„å¢ƒåœ–", use_column_width=True)
                            except Exception as e:
                                st.error(f"DALLÂ·E åœ–ç‰‡ç”Ÿæˆå¤±æ•—ï¼š{e}")
                    
                    elif not openai_api_key and not google_api_key and "Pollinations" not in image_model_choice:
                        st.info("â„¹ï¸ è«‹åœ¨å·¦å´è¼¸å…¥å°æ‡‰çš„ API Keyï¼Œæˆ–è€…é¸æ“‡ Pollinations å…é‘°åŒ™æ¨¡å¼ï¼")

            except Exception as e:
               st.error(f"é€£ç·šéŒ¯èª¤ï¼š{e} (è«‹æª¢æŸ¥ API Key æ˜¯å¦æ­£ç¢º)")
               # streamlit run app.py
